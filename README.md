# My LLM Knowledge Base

This repository is a comprehensive knowledge base dedicated to documenting my learning journey through the world of Large Language Models (LLMs). It serves as a structured collection of **notes, summaries, numerical exercises, model analyses, practical applications, and insights** gathered from lectures, papers, textbooks, and hands-on projects.

---

## ğŸ¯ Goal

The primary goal of this repository is to build a deep, structured understanding of LLMs, from their foundational principles to their most advanced applications. This serves a dual purpose:

**For Me:** A personal reference that tracks my progress and solidifies my knowledge as I advance through my LLM learning journey.

**For Others:** A comprehensive, well-organized resource that can help fellow learners, students, and practitioners understand LLMs more effectively. By sharing my notes and insights, I hope to contribute to the broader learning community.

Whether you're just starting your journey with LLMs or looking to deepen your understanding of specific concepts, this repository aims to be a valuable companion in your learning process.

---

## ğŸ“‚ Repository Structure

The repository is organized into several key directories to separate different types of information:

*   **`ğŸ§  Concepts_and_Theory/`**: Contains the core theoretical notes from lectures and readings. This forms the foundational knowledge base.
*   **`ğŸ”¢ Numerical_Practice/`**: A dedicated space for numerical exercises, calculations, and practice problems to reinforce theoretical concepts.
*   **`ğŸ“¦ Models/`**: Notes and deep dives into specific LLMs, such as the GPT series, Llama, Gemini, and other important open-source models.
*   **`ğŸš€ Applications/`**: Explores real-world applications of LLMs, including chatbots, code generation, summarization, and their use in various industries.
*   **`ğŸ› ï¸ Tools_and_Frameworks/`**: Notes on the ecosystem surrounding LLMs, including libraries like Hugging Face, frameworks like LangChain, and vector databases.
*   **`ğŸ”¨ Build_Your_Own_LLM/`**: Step-by-step guides and notes for building Large Language Models from scratch, including implementation details and code examples.
*   **`ğŸ“œ Paper_Summaries/`**: Summaries and analyses of seminal research papers in the field of NLP and LLMs (e.g., "Attention Is All You Need").

---

## ğŸŒ± Our Learning Philosophy

These notes are personally crafted by me from the articles I read, classes I attend, and textbooks I study, and I hope they will be valuable for you too!

LLMs are a fun subject, so learning about them shouldn't be boring. To make the process more engaging, I'll be using elements like:
*   Flowcharts ğŸ“Š to visualize complex ideas
*   Real-world analogies ğŸ’¡ to make concepts stick
*   Emojis ğŸ¥³ to add some personality

Let's make our learning productive and enjoyable! ğŸš€

---

## ğŸ“š Key References

This knowledge base draws insights from several excellent textbooks, research papers, and the classes I attend:

### Classes & Courses
- **Dr. Murari Mandal** - I attend his classes on "Introduction to Large Language Models"
- **NPTEL Course: Large Language Models** - IIT Delhi & IIT Bombay
  - Instructors: Prof. Tanmoy Chakraborty (IIT Delhi) & Prof. Soumen Chakrabarti (IIT Bombay)

### Textbooks & Resources
- **Introduction to Large Language Models** - Tanmoy Chakraborty
- **Speech and Language Processing (3rd ed. draft)** - Dan Jurafsky and James H. Martin
- **LLM Engineer's Handbook** - Maxime Labonne and Paul Iusztin
- **Hands-On Large Language Models** - Jay Alammar
- **Build a Large Language Model (From Scratch)** - Sebastian Raschka

---

*This project was initiated on August 10, 2025.*
